{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "#Student name: Sally Moywaywa\n",
    "#Cohort: 3\n",
    "#loading required libraries\n",
    "import pandas                    as pd \n",
    "import matplotlib.pyplot         as plt \n",
    "import seaborn                   as sns \n",
    "import random                    as rand\n",
    "import statsmodels.formula.api   as smf \n",
    "from   sklearn.model_selection   import train_test_split \n",
    "from   sklearn.ensemble          import GradientBoostingRegressor\n",
    "import sklearn.linear_model\n",
    "from   sklearn.neighbors         import KNeighborsRegressor \n",
    "from   sklearn.preprocessing     import StandardScaler \n",
    "from   sklearn.linear_model      import LogisticRegression  \n",
    "from   sklearn.metrics           import confusion_matrix         \n",
    "from   sklearn.metrics           import roc_auc_score            \n",
    "from   sklearn.neighbors         import KNeighborsClassifier \n",
    "from   sklearn.tree              import DecisionTreeClassifier      \n",
    "from   sklearn.tree              import export_graphviz             \n",
    "from   sklearn.externals.six     import StringIO           \n",
    "from   IPython.display           import Image                    \n",
    "import pydotplus                                     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "original_df = pd.read_excel('Apprentice_Chef_Dataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an empty list where the split email domains would be appended\n",
    "list1 = []\n",
    "\n",
    "# creating a loop that will loop over the email column, split the emails and append them to the empty list\n",
    "for index, col in original_df.iterrows():\n",
    "    \n",
    "    email_split = original_df.loc[index, 'EMAIL'].split(sep = '@')\n",
    "    \n",
    "    list1.append(email_split)\n",
    "    \n",
    "\n",
    "#making the split email domain list into a dataframe\n",
    "emails_df = pd.DataFrame(list1)\n",
    "\n",
    "# linking the email_dataframe with apprentice chef DataFrame\n",
    "# we re-read the oringinal dataset to prevent chances of linking the two dataframes multiple times\n",
    "original_df = pd.read_excel(\"Apprentice_Chef_Dataset.xlsx\")\n",
    "\n",
    "\n",
    "# renaming the columns of the split email domain dataframe\n",
    "emails_df.columns = ['NAME' ,'EMAIL_DOMAINS']\n",
    "\n",
    "# linking the emails dataframe to the original dataframe\n",
    "original_df = pd.concat([original_df, emails_df['EMAIL_DOMAINS']],\n",
    "               axis = 1)\n",
    "\n",
    "#creating the different email groups i.e professional, personal or junk as stated by the marketing team \n",
    "\n",
    "professional_emails = ['@mmm.com', '@amex.com','@apple.com', '@boeing.com',\n",
    "                       '@caterpillar.com', '@chevron.com', '@cisco.com',\n",
    "                       '@cocacola.com', '@disney.com', '@dupont.com', \n",
    "                       '@exxon.com', '@ge.org', '@goldmansacs.com', \n",
    "                       '@homedepot.com', '@ibm.com', '@intel.com', \n",
    "                       '@jnj.com', '@jpmorgan.com', '@mcdonalds.com',\n",
    "                       '@merck.com', '@microsoft.com', '@nike.com', \n",
    "                       '@pfizer.com','@pg.com', '@travelers.com', \n",
    "                       '@unitedtech.com', '@unitedhealth.com',\n",
    "                       '@verizon.com', '@visa.com', '@walmart.com']\n",
    "\n",
    "personal_emails    = ['@gmail.com', '@yahoo.com', '@protonmail.com']\n",
    "\n",
    "junk_emails        = ['@me.com', '@aol.com', '@hotmail.com',\n",
    "                      '@live.com', '@msn.com', '@passport.com']\n",
    "\n",
    "#creating an empty list where the email domains groups would be appended\n",
    "list2 = []\n",
    "\n",
    "# creating a loop that will loop over the email domains column, group the email domains and append them to the empty list\n",
    "\n",
    "for domain in original_df['EMAIL_DOMAINS']:\n",
    "        if '@' + domain in professional_emails: \n",
    "            list2.append('professional')\n",
    "            \n",
    "        elif '@' + domain in personal_emails:\n",
    "            list2.append('personal')\n",
    "            \n",
    "        elif '@' + domain in junk_emails:\n",
    "            list2.append('junk')\n",
    "            \n",
    "\n",
    "# adding the list to the original dataframe\n",
    "original_df['EMAIL_DOMAINS'] = pd.Series(list2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling in missing values\n",
    "# creating an imputation value that will be filled in place of missing data\n",
    "fill = \"N/A\"\n",
    "\n",
    "\n",
    "# imputing 'FAMILY_NAME'\n",
    "original_df['FAMILY_NAME'] = original_df['FAMILY_NAME'].fillna(fill)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting outlier thresholds\n",
    "TOTAL_MEALS_ORDERED_hi          = 300\n",
    "UNIQUE_MEALS_PURCH_hi           = 8\n",
    "CONTACTS_W_CUSTOMER_SERVICE_hi  = 10\n",
    "AVG_TIME_PER_SITE_VISIT_hi      = 250\n",
    "CANCELLATIONS_BEFORE_NOON_hi    = 6\n",
    "EARLY_DELIVERIES_hi             = 5\n",
    "EARLY_DELIVERIES_lo             = 1\n",
    "LATE_DELIVERIES_hi              = 12.5\n",
    "AVG_PREP_VID_TIME_hi            = 300\n",
    "AVG_CLICKS_PER_VISIT_lo         = 7.5\n",
    "TOTAL_PHOTOS_VIEWED_hi          = 750\n",
    "\n",
    "# developing new columns for outlier values in the dataset\n",
    "\n",
    "\n",
    "\n",
    "# TOTAL_MEALS_ORDERED\n",
    "original_df['out_TOTAL_MEALS_ORDERED'] = 0\n",
    "condition_hi = original_df.loc[0:,'out_TOTAL_MEALS_ORDERED'][original_df['TOTAL_MEALS_ORDERED'] > TOTAL_MEALS_ORDERED_hi]\n",
    "\n",
    "original_df['out_TOTAL_MEALS_ORDERED'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# UNIQUE_MEALS_PURCH\n",
    "original_df['out_UNIQUE_MEALS_PURCH'] = 0\n",
    "condition_hi = original_df.loc[0:,'out_UNIQUE_MEALS_PURCH'][original_df['UNIQUE_MEALS_PURCH'] < UNIQUE_MEALS_PURCH_hi]\n",
    "\n",
    "original_df['out_UNIQUE_MEALS_PURCH'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# CONTACTS_W_CUSTOMER_SERVICE\n",
    "original_df['out_CONTACTS_W_CUSTOMER_SERVICE'] = 0\n",
    "condition_hi = original_df.loc[0:,'out_CONTACTS_W_CUSTOMER_SERVICE'][original_df['CONTACTS_W_CUSTOMER_SERVICE'] > CONTACTS_W_CUSTOMER_SERVICE_hi]\n",
    "\n",
    "original_df['out_CONTACTS_W_CUSTOMER_SERVICE'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# AVG_TIME_PER_SITE_VISIT\n",
    "original_df['out_AVG_TIME_PER_SITE_VISIT'] = 0\n",
    "condition_hi = original_df.loc[0:,'out_AVG_TIME_PER_SITE_VISIT'][original_df['AVG_TIME_PER_SITE_VISIT'] > AVG_TIME_PER_SITE_VISIT_hi]\n",
    "\n",
    "original_df['out_AVG_TIME_PER_SITE_VISIT'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# CANCELLATIONS_BEFORE_NOON\n",
    "original_df['out_CANCELLATIONS_BEFORE_NOON'] = 0\n",
    "condition_hi = original_df.loc[0:,'out_CANCELLATIONS_BEFORE_NOON'][original_df['CANCELLATIONS_BEFORE_NOON'] > CANCELLATIONS_BEFORE_NOON_hi]\n",
    "\n",
    "original_df['out_CANCELLATIONS_BEFORE_NOON'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# EARLY_DELIVERIES\n",
    "original_df['out_EARLY_DELIVERIES'] = 0\n",
    "condition_hi = original_df.loc[0:,'out_EARLY_DELIVERIES'][original_df['EARLY_DELIVERIES'] > EARLY_DELIVERIES_hi]\n",
    "condition_lo = original_df.loc[0:,'out_EARLY_DELIVERIES'][original_df['EARLY_DELIVERIES'] < EARLY_DELIVERIES_lo]\n",
    "\n",
    "original_df['out_EARLY_DELIVERIES'].replace(to_replace = condition_hi,\n",
    "                                 value      = 1,\n",
    "                                 inplace    = True)\n",
    "\n",
    "original_df['out_EARLY_DELIVERIES'].replace(to_replace = condition_lo,\n",
    "                                 value      = 1,\n",
    "                                 inplace    = True)\n",
    "\n",
    "\n",
    "# LATE_DELIVERIES\n",
    "original_df['out_LATE_DELIVERIES'] = 0\n",
    "condition_hi = original_df.loc[0:,'out_LATE_DELIVERIES'][original_df['LATE_DELIVERIES'] > LATE_DELIVERIES_hi]\n",
    "\n",
    "original_df['out_LATE_DELIVERIES'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "# AVG_PREP_VID_TIME\n",
    "original_df['out_AVG_PREP_VID_TIME'] = 0\n",
    "condition_hi = original_df.loc[0:,'out_AVG_PREP_VID_TIME'][original_df['AVG_PREP_VID_TIME'] > AVG_PREP_VID_TIME_hi]\n",
    "\n",
    "original_df['out_AVG_PREP_VID_TIME'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# AVG_CLICKS_PER_VISIT\n",
    "original_df['out_AVG_CLICKS_PER_VISIT'] = 0\n",
    "condition_lo = original_df.loc[0:,'out_AVG_CLICKS_PER_VISIT'][original_df['AVG_CLICKS_PER_VISIT'] > AVG_CLICKS_PER_VISIT_lo]\n",
    "\n",
    "original_df['out_AVG_CLICKS_PER_VISIT'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# TOTAL_PHOTOS_VIEWED\n",
    "original_df['out_TOTAL_PHOTOS_VIEWED'] = 0\n",
    "condition_hi = original_df.loc[0:,'out_TOTAL_PHOTOS_VIEWED'][original_df['TOTAL_PHOTOS_VIEWED'] > TOTAL_PHOTOS_VIEWED_hi]\n",
    "\n",
    "original_df['out_TOTAL_PHOTOS_VIEWED'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring explanatory variables \n",
    "x_variables ={\n",
    "    #original variables used to build the model\n",
    "    \n",
    "    'Original' : ['TOTAL_MEALS_ORDERED', 'CONTACTS_W_CUSTOMER_SERVICE','AVG_TIME_PER_SITE_VISIT',\n",
    "                  'CANCELLATIONS_BEFORE_NOON','CANCELLATIONS_AFTER_NOON','TASTES_AND_PREFERENCES',\n",
    "                  'PC_LOGINS','MOBILE_LOGINS', 'WEEKLY_PLAN','EARLY_DELIVERIES','LATE_DELIVERIES',\n",
    "                  'PACKAGE_LOCKER','REFRIGERATED_LOCKER','FOLLOWED_RECOMMENDATIONS_PCT','AVG_PREP_VID_TIME',\n",
    "                  'LARGEST_ORDER_SIZE','MASTER_CLASSES_ATTENDED','MEDIAN_MEAL_RATING','AVG_CLICKS_PER_VISIT',\n",
    "                  'TOTAL_PHOTOS_VIEWED','out_TOTAL_MEALS_ORDERED','out_UNIQUE_MEALS_PURCH',\n",
    "                  'out_CONTACTS_W_CUSTOMER_SERVICE','out_AVG_TIME_PER_SITE_VISIT','out_CANCELLATIONS_BEFORE_NOON',\n",
    "                  'out_EARLY_DELIVERIES','out_LATE_DELIVERIES','out_AVG_PREP_VID_TIME'],\n",
    "    \n",
    "    #significant variables after logistic regression\n",
    "    'Significant' : ['CANCELLATIONS_BEFORE_NOON', 'TASTES_AND_PREFERENCES',\n",
    "                     'MOBILE_LOGINS','FOLLOWED_RECOMMENDATIONS_PCT']\n",
    "}\n",
    "\n",
    "# declaring response variables and explanatory variable\n",
    "\n",
    "chef_data   =  original_df.loc[ : , x_variables['Significant']]\n",
    "chef_target =  original_df.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "\n",
    "#preparing the training and testing data\n",
    "X_train,X_test, y_train, y_test = train_test_split(\n",
    "            chef_data,\n",
    "            chef_target,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 222,\n",
    "            stratify     = chef_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7868\n",
      "Testing  ACCURACY: 0.7721\n",
      "AUC Score        : 0.7612\n"
     ]
    }
   ],
   "source": [
    "#Instantiating the full tree classification model\n",
    "Chef_tree2  = DecisionTreeClassifier(max_depth = 4,\n",
    "                                     min_samples_leaf = 25,\n",
    "                                     random_state = 802)\n",
    "\n",
    "\n",
    "#Fitting the model on the training data\n",
    "Chef_tree2_fit  = Chef_tree2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Predicting on new data using full tree classification model\n",
    "Chef_tree2_pred = Chef_tree2_fit.predict(X_test)\n",
    "\n",
    "#Scoring the results of the model\n",
    "pruned_tree_train = Chef_tree2_fit.score(X_train, y_train).round(4)\n",
    "pruned_tree_test = Chef_tree2_fit.score(X_test, y_test).round(4)\n",
    "pruned_tree_AUC = roc_auc_score(y_true  = y_test, y_score = Chef_tree2_pred).round(4)\n",
    "\n",
    "#Printing the scoring results of the model\n",
    "print('Training ACCURACY:', Chef_tree2_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', Chef_tree2_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test, y_score = Chef_tree2_pred).round(4))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
